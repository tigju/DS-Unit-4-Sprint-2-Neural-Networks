{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, Ftrl, Adamax, SGD\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "telecom = pd.read_csv('telecom-customer-churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0  Electronic check          29.85         29.85    No  \n",
       "1      Mailed check          56.95        1889.5    No  \n",
       "2      Mailed check          53.85        108.15   Yes  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(telecom.shape)\n",
    "telecom.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom['Churn'] = [1 if c == 'Yes' else 0 for c in telecom['Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7038    0\n",
       "7039    0\n",
       "7040    0\n",
       "7041    1\n",
       "7042    0\n",
       "Name: Churn, Length: 7043, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom = telecom.replace('^\\s*$', -2, regex=True)\n",
    "telecom.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom['TotalCharges'] = pd.to_numeric(telecom['TotalCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom = telecom.drop(columns=['customerID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
       "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
       "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
       "       'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "        'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
       "        'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
       "        'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
       "        'MonthlyCharges', 'TotalCharges'],\n",
       "       dtype='object'),\n",
       " 'Churn')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = telecom.columns[:-1]\n",
    "target = telecom.columns[-1]\n",
    "features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7043, 19), (7043,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = telecom[features]\n",
    "y = telecom[target]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((5282, 19), (5282,)), ((1761, 19), (1761,)))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
       "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
       "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
       "       'PaperlessBilling', 'PaymentMethod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = telecom[features].select_dtypes(include=['object']).columns\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ce.OrdinalEncoder()\n",
    "\n",
    "\n",
    "X_train_enc = enc.fit_transform(X_train, y_train)\n",
    "X_test_enc = enc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 19)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.15</td>\n",
       "      <td>525.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.05</td>\n",
       "      <td>85.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>76.00</td>\n",
       "      <td>2215.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>75.10</td>\n",
       "      <td>270.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>91.10</td>\n",
       "      <td>2198.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.15</td>\n",
       "      <td>306.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.45</td>\n",
       "      <td>1200.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19.80</td>\n",
       "      <td>457.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "6607       1              0        1           1       1             1   \n",
       "2598       2              0        1           2       7             2   \n",
       "2345       2              0        1           1       4             2   \n",
       "4093       2              0        1           2      29             2   \n",
       "693        2              0        1           2       3             2   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "3772       1              0        2           2       1             2   \n",
       "5191       2              0        2           1      23             2   \n",
       "5226       1              0        2           1      12             2   \n",
       "5390       1              1        1           2      12             2   \n",
       "860        1              0        1           2      26             2   \n",
       "\n",
       "      MultipleLines  InternetService  OnlineSecurity  OnlineBackup  \\\n",
       "6607              1                1               1             1   \n",
       "2598              2                2               1             1   \n",
       "2345              2                3               2             2   \n",
       "4093              3                2               1             1   \n",
       "693               3                2               1             1   \n",
       "...             ...              ...             ...           ...   \n",
       "3772              2                2               3             1   \n",
       "5191              3                1               3             3   \n",
       "5226              2                3               2             2   \n",
       "5390              3                2               1             1   \n",
       "860               2                3               2             2   \n",
       "\n",
       "      DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
       "6607                 1            1            1                1         1   \n",
       "2598                 2            1            1                1         1   \n",
       "2345                 3            2            2                2         1   \n",
       "4093                 1            1            1                1         1   \n",
       "693                  1            1            1                1         1   \n",
       "...                ...          ...          ...              ...       ...   \n",
       "3772                 1            1            3                3         1   \n",
       "5191                 2            3            3                3         3   \n",
       "5226                 3            2            2                2         1   \n",
       "5390                 2            1            3                3         1   \n",
       "860                  3            2            2                2         2   \n",
       "\n",
       "      PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "6607                 1              1           25.30         25.30  \n",
       "2598                 1              1           75.15        525.00  \n",
       "2345                 1              2           20.05         85.50  \n",
       "4093                 1              3           76.00       2215.25  \n",
       "693                  1              3           75.10        270.70  \n",
       "...                ...            ...             ...           ...  \n",
       "3772                 1              1           95.00         95.00  \n",
       "5191                 1              3           91.10       2198.30  \n",
       "5226                 1              1           21.15        306.05  \n",
       "5390                 1              1           99.45       1200.15  \n",
       "860                  2              3           19.80        457.30  \n",
       "\n",
       "[5282 rows x 19 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97309929 -0.43609145 -0.96941854 -1.5265618  -1.28288214 -3.06222308\n",
      "  -2.06867715 -1.18104467 -0.91809493 -1.03965454 -0.99221753 -0.92219807\n",
      "  -1.11971672 -1.12523148 -0.83139487 -0.83766059 -1.14934396 -1.31004561\n",
      "  -0.99706287]\n",
      " [ 1.02764436 -0.43609145 -0.96941854  0.65506683 -1.03785653  0.32656014\n",
      "  -0.51525766  0.17245456 -0.91809493 -1.03965454  0.28886118 -0.92219807\n",
      "  -1.11971672 -1.12523148 -0.83139487 -0.83766059 -1.14934396  0.34483164\n",
      "  -0.77679203]\n",
      " [ 1.02764436 -0.43609145 -0.96941854 -1.5265618  -1.16036933  0.32656014\n",
      "  -0.51525766  1.52595379  0.2459419   0.09588212  1.56993989  0.24034374\n",
      "   0.01070066  0.00513609 -0.83139487 -0.83766059 -0.28945235 -1.48433058\n",
      "  -0.97052633]\n",
      " [ 1.02764436 -0.43609145 -0.96941854  0.65506683 -0.13942926  0.32656014\n",
      "   1.03816184  0.17245456 -0.91809493 -1.03965454 -0.99221753 -0.92219807\n",
      "  -1.11971672 -1.12523148 -0.83139487 -0.83766059  0.57043927  0.37304921\n",
      "  -0.03171942]\n",
      " [ 1.02764436 -0.43609145 -0.96941854  0.65506683 -1.20120694  0.32656014\n",
      "   1.03816184  0.17245456 -0.91809493 -1.03965454 -0.99221753 -0.92219807\n",
      "  -1.11971672 -1.12523148 -0.83139487 -0.83766059  0.57043927  0.34317178\n",
      "  -0.88888903]\n",
      " [ 1.02764436  2.293097   -0.96941854  0.65506683 -1.28288214 -3.06222308\n",
      "  -2.06867715 -1.18104467 -0.91809493 -1.03965454 -0.99221753 -0.92219807\n",
      "  -1.11971672 -1.12523148 -0.83139487 -0.83766059  1.43033088 -1.29344704\n",
      "  -0.99684246]\n",
      " [-0.97309929 -0.43609145 -0.96941854  0.65506683 -1.03785653 -3.06222308\n",
      "  -2.06867715 -1.18104467  1.40997873 -1.03965454  0.28886118 -0.92219807\n",
      "  -1.11971672 -1.12523148  0.37107712  1.19380095  1.43033088 -0.97807425\n",
      "  -0.89148979]\n",
      " [ 1.02764436 -0.43609145 -0.96941854  0.65506683  0.79983561  0.32656014\n",
      "   1.03816184  0.17245456  1.40997873  1.23141878 -0.99221753  1.40288556\n",
      "   1.14111803  1.13550366  0.37107712 -0.83766059  0.57043927  1.54324827\n",
      "   1.59979233]\n",
      " [-0.97309929 -0.43609145  1.03154619 -1.5265618   1.61658768  0.32656014\n",
      "   1.03816184 -1.18104467  1.40997873  1.23141878  0.28886118  1.40288556\n",
      "   1.14111803  1.13550366  1.57354911 -0.83766059  0.57043927  0.90254353\n",
      "   1.90767339]\n",
      " [-0.97309929 -0.43609145  1.03154619  0.65506683  0.92234842  0.32656014\n",
      "   1.03816184  0.17245456  1.40997873  1.23141878 -0.99221753 -0.92219807\n",
      "   1.14111803 -1.12523148 -0.83139487 -0.83766059 -1.14934396  1.06188979\n",
      "   1.30112412]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_enc)\n",
    "X_test_scaled = scaler.transform(X_test_enc)\n",
    "print(X_train_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 19)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185     1\n",
       "2715    0\n",
       "3825    0\n",
       "1807    1\n",
       "132     0\n",
       "       ..\n",
       "5845    1\n",
       "2301    0\n",
       "5121    0\n",
       "677     1\n",
       "6062    0\n",
       "Name: Churn, Length: 1761, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, input_dim=19),\n",
    "    Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/166 [==============================] - 1s 4ms/step - loss: 4.6622 - accuracy: 0.4250 - val_loss: 4.1593 - val_accuracy: 0.4157\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 3.7452 - accuracy: 0.4339 - val_loss: 3.2267 - val_accuracy: 0.4287\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 3.1162 - accuracy: 0.4428 - val_loss: 2.8138 - val_accuracy: 0.4526\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 2.6643 - accuracy: 0.4587 - val_loss: 2.4912 - val_accuracy: 0.4622\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 2.4236 - accuracy: 0.4744 - val_loss: 2.3474 - val_accuracy: 0.4747\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 2.3234 - accuracy: 0.4769 - val_loss: 2.1687 - val_accuracy: 0.4713\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 2.0939 - accuracy: 0.4786 - val_loss: 1.9158 - val_accuracy: 0.4804\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 1.8481 - accuracy: 0.4945 - val_loss: 1.6293 - val_accuracy: 0.4861\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 1.5420 - accuracy: 0.5051 - val_loss: 1.3565 - val_accuracy: 0.5116\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 0s 3ms/step - loss: 1.2990 - accuracy: 0.5178 - val_loss: 1.1458 - val_accuracy: 0.5173\n"
     ]
    }
   ],
   "source": [
    "model_object = model.fit(x=X_train_scaled, \n",
    "          y=y_train, \n",
    "          epochs=10, \n",
    "          validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline is 51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(lr, activation='relu'):\n",
    "    # create optimizer\n",
    "    adam = Adam(learning_rate=lr)\n",
    "    # create model\n",
    "    act = activation\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=19, activation=act))\n",
    "    model.add(Dense(32, activation=act))\n",
    "    model.add(Dense(16, activation=act))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.add(Dense(2, activation=act))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model2 = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7351362347602844 using {'batch_size': 10, 'epochs': 20, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'lr': [.001, .01, .1, .2, .3, .5],\n",
    "              'batch_size': [10],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, n_jobs=12)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6512347280979156 using {'batch_size': 30, 'epochs': 20, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'lr': [.2],\n",
    "              'batch_size': [10, 20, 30, 40, 50],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, n_jobs=12)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7368407845497131 using {'batch_size': 10, 'epochs': 50, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'lr': [.2],\n",
    "              'batch_size': [10, 20, 30, 40, 50],\n",
    "              'epochs': [20, 50, 100]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, n_jobs=12)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7368407845497131 using {'activation': 'relu', 'batch_size': 10, 'epochs': 50, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'lr': [.2],\n",
    "              'batch_size': [10],\n",
    "              'epochs': [50],\n",
    "              'activation': ['relu', 'softmax', 'softplus']}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, n_jobs=12)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: 0.5504771530628204, Stdev: 0.2317484118798782 with: {'batch_size': 10, 'epochs': 20, 'lr': 0.2}\n",
      "Means: 0.7368407845497131, Stdev: 0.012716509457793904 with: {'batch_size': 10, 'epochs': 50, 'lr': 0.2}\n",
      "Means: 0.5016507804393768, Stdev: 0.21311348698165491 with: {'batch_size': 10, 'epochs': 100, 'lr': 0.2}\n",
      "Means: 0.6390167593955993, Stdev: 0.1921707767743572 with: {'batch_size': 20, 'epochs': 20, 'lr': 0.2}\n",
      "Means: 0.5504771530628204, Stdev: 0.2317484118798782 with: {'batch_size': 20, 'epochs': 50, 'lr': 0.2}\n",
      "Means: 0.642422616481781, Stdev: 0.1896603942666927 with: {'batch_size': 20, 'epochs': 100, 'lr': 0.2}\n",
      "Means: 0.556158971786499, Stdev: 0.23043750153031653 with: {'batch_size': 30, 'epochs': 20, 'lr': 0.2}\n",
      "Means: 0.5439410030841827, Stdev: 0.23307607753767434 with: {'batch_size': 30, 'epochs': 50, 'lr': 0.2}\n",
      "Means: 0.5410074532032013, Stdev: 0.23361005640635293 with: {'batch_size': 30, 'epochs': 100, 'lr': 0.2}\n",
      "Means: 0.7368407845497131, Stdev: 0.012716509457793904 with: {'batch_size': 40, 'epochs': 20, 'lr': 0.2}\n",
      "Means: 0.4583349466323853, Stdev: 0.23349367347216338 with: {'batch_size': 40, 'epochs': 50, 'lr': 0.2}\n",
      "Means: 0.35861374735832213, Stdev: 0.19000995188329783 with: {'batch_size': 40, 'epochs': 100, 'lr': 0.2}\n",
      "Means: 0.7368407845497131, Stdev: 0.012716509457793904 with: {'batch_size': 50, 'epochs': 20, 'lr': 0.2}\n",
      "Means: 0.6417650282382965, Stdev: 0.19015242949009917 with: {'batch_size': 50, 'epochs': 50, 'lr': 0.2}\n",
      "Means: 0.443841016292572, Stdev: 0.23043748694138858 with: {'batch_size': 50, 'epochs': 100, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params\n",
    "param_grid = {'lr': [.2],\n",
    "              'batch_size': [10],\n",
    "              'epochs': [50]}\n",
    "\n",
    "# early stopping\n",
    "stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10)\n",
    "\n",
    "model_2 = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=19),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='relu')\n",
    "])\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.2), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 3.0850 - accuracy: 0.80 - ETA: 0s - loss: 4.3615 - accuracy: 0.71 - ETA: 0s - loss: 4.3447 - accuracy: 0.71 - ETA: 0s - loss: 4.2289 - accuracy: 0.72 - ETA: 0s - loss: 4.2162 - accuracy: 0.72 - ETA: 0s - loss: 4.2616 - accuracy: 0.72 - ETA: 0s - loss: 4.2439 - accuracy: 0.72 - ETA: 0s - loss: 4.1917 - accuracy: 0.72 - ETA: 0s - loss: 4.0438 - accuracy: 0.73 - ETA: 0s - loss: 3.9991 - accuracy: 0.74 - ETA: 0s - loss: 4.0133 - accuracy: 0.73 - ETA: 0s - loss: 4.0371 - accuracy: 0.73 - ETA: 0s - loss: 4.0037 - accuracy: 0.74 - ETA: 0s - loss: 4.0056 - accuracy: 0.74 - ETA: 0s - loss: 4.0602 - accuracy: 0.73 - ETA: 0s - loss: 4.0668 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 1.5425 - accuracy: 0.90 - ETA: 0s - loss: 4.2308 - accuracy: 0.72 - ETA: 0s - loss: 4.3016 - accuracy: 0.72 - ETA: 0s - loss: 4.3103 - accuracy: 0.72 - ETA: 0s - loss: 4.3099 - accuracy: 0.72 - ETA: 0s - loss: 4.2765 - accuracy: 0.72 - ETA: 0s - loss: 4.2457 - accuracy: 0.72 - ETA: 0s - loss: 4.1628 - accuracy: 0.73 - ETA: 0s - loss: 4.1774 - accuracy: 0.72 - ETA: 0s - loss: 4.2286 - accuracy: 0.72 - ETA: 0s - loss: 4.1959 - accuracy: 0.72 - ETA: 0s - loss: 4.1197 - accuracy: 0.73 - ETA: 0s - loss: 4.1018 - accuracy: 0.73 - ETA: 0s - loss: 4.0736 - accuracy: 0.73 - ETA: 0s - loss: 4.0472 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 4.6275 - accuracy: 0.70 - ETA: 0s - loss: 2.9968 - accuracy: 0.80 - ETA: 0s - loss: 3.5454 - accuracy: 0.77 - ETA: 0s - loss: 3.6195 - accuracy: 0.76 - ETA: 0s - loss: 3.6791 - accuracy: 0.76 - ETA: 0s - loss: 3.8425 - accuracy: 0.75 - ETA: 0s - loss: 3.9352 - accuracy: 0.74 - ETA: 0s - loss: 3.9637 - accuracy: 0.74 - ETA: 0s - loss: 3.9797 - accuracy: 0.74 - ETA: 0s - loss: 4.0163 - accuracy: 0.73 - ETA: 0s - loss: 4.0259 - accuracy: 0.73 - ETA: 0s - loss: 4.0399 - accuracy: 0.73 - ETA: 0s - loss: 4.0147 - accuracy: 0.73 - ETA: 0s - loss: 4.0530 - accuracy: 0.73 - ETA: 0s - loss: 4.0592 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 6.1700 - accuracy: 0.60 - ETA: 0s - loss: 3.3768 - accuracy: 0.78 - ETA: 0s - loss: 3.8562 - accuracy: 0.75 - ETA: 0s - loss: 3.9290 - accuracy: 0.74 - ETA: 0s - loss: 3.9009 - accuracy: 0.74 - ETA: 0s - loss: 3.8913 - accuracy: 0.74 - ETA: 0s - loss: 3.9958 - accuracy: 0.74 - ETA: 0s - loss: 3.9935 - accuracy: 0.74 - ETA: 0s - loss: 3.9753 - accuracy: 0.74 - ETA: 0s - loss: 3.9442 - accuracy: 0.74 - ETA: 0s - loss: 3.9768 - accuracy: 0.74 - ETA: 0s - loss: 4.0480 - accuracy: 0.73 - ETA: 0s - loss: 4.0788 - accuracy: 0.73 - ETA: 0s - loss: 3.9944 - accuracy: 0.74 - ETA: 0s - loss: 4.0054 - accuracy: 0.74 - ETA: 0s - loss: 4.0572 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.00 - ETA: 0s - loss: 4.6275 - accuracy: 0.7000   - ETA: 0s - loss: 4.3704 - accuracy: 0.71 - ETA: 0s - loss: 4.2906 - accuracy: 0.72 - ETA: 0s - loss: 4.2892 - accuracy: 0.72 - ETA: 0s - loss: 4.1978 - accuracy: 0.72 - ETA: 0s - loss: 4.1409 - accuracy: 0.73 - ETA: 0s - loss: 4.1237 - accuracy: 0.73 - ETA: 0s - loss: 4.0808 - accuracy: 0.73 - ETA: 0s - loss: 4.0420 - accuracy: 0.73 - ETA: 0s - loss: 3.9777 - accuracy: 0.74 - ETA: 0s - loss: 4.0332 - accuracy: 0.73 - ETA: 0s - loss: 4.0641 - accuracy: 0.73 - ETA: 0s - loss: 4.0935 - accuracy: 0.73 - ETA: 0s - loss: 4.0490 - accuracy: 0.73 - ETA: 0s - loss: 4.0644 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 3.0850 - accuracy: 0.80 - ETA: 0s - loss: 3.6869 - accuracy: 0.76 - ETA: 0s - loss: 3.6869 - accuracy: 0.76 - ETA: 0s - loss: 3.7351 - accuracy: 0.75 - ETA: 0s - loss: 3.8186 - accuracy: 0.75 - ETA: 0s - loss: 3.8450 - accuracy: 0.75 - ETA: 0s - loss: 3.8195 - accuracy: 0.75 - ETA: 0s - loss: 3.8909 - accuracy: 0.74 - ETA: 0s - loss: 3.8983 - accuracy: 0.74 - ETA: 0s - loss: 3.9074 - accuracy: 0.74 - ETA: 0s - loss: 4.0143 - accuracy: 0.73 - ETA: 0s - loss: 4.0196 - accuracy: 0.73 - ETA: 0s - loss: 4.0645 - accuracy: 0.73 - ETA: 0s - loss: 4.0597 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 6.1700 - accuracy: 0.60 - ETA: 0s - loss: 3.9947 - accuracy: 0.74 - ETA: 0s - loss: 3.9091 - accuracy: 0.74 - ETA: 0s - loss: 3.8775 - accuracy: 0.74 - ETA: 0s - loss: 3.8985 - accuracy: 0.74 - ETA: 0s - loss: 4.0088 - accuracy: 0.74 - ETA: 0s - loss: 4.1018 - accuracy: 0.73 - ETA: 0s - loss: 4.0800 - accuracy: 0.73 - ETA: 0s - loss: 4.0389 - accuracy: 0.73 - ETA: 0s - loss: 4.0007 - accuracy: 0.74 - ETA: 0s - loss: 4.0185 - accuracy: 0.73 - ETA: 0s - loss: 4.0367 - accuracy: 0.73 - ETA: 0s - loss: 4.0566 - accuracy: 0.73 - ETA: 0s - loss: 4.0621 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 3.0850 - accuracy: 0.80 - ETA: 0s - loss: 4.0342 - accuracy: 0.73 - ETA: 0s - loss: 4.0192 - accuracy: 0.73 - ETA: 0s - loss: 4.0584 - accuracy: 0.73 - ETA: 0s - loss: 4.0717 - accuracy: 0.73 - ETA: 0s - loss: 3.9499 - accuracy: 0.74 - ETA: 0s - loss: 4.0813 - accuracy: 0.73 - ETA: 0s - loss: 4.0923 - accuracy: 0.73 - ETA: 0s - loss: 4.1461 - accuracy: 0.73 - ETA: 0s - loss: 4.1555 - accuracy: 0.73 - ETA: 0s - loss: 4.1031 - accuracy: 0.73 - ETA: 0s - loss: 4.0669 - accuracy: 0.73 - ETA: 0s - loss: 4.0577 - accuracy: 0.73 - ETA: 0s - loss: 4.0754 - accuracy: 0.73 - ETA: 0s - loss: 4.0988 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 4.6275 - accuracy: 0.70 - ETA: 0s - loss: 3.8156 - accuracy: 0.75 - ETA: 0s - loss: 3.8888 - accuracy: 0.74 - ETA: 0s - loss: 3.8639 - accuracy: 0.74 - ETA: 0s - loss: 3.8786 - accuracy: 0.74 - ETA: 0s - loss: 3.8819 - accuracy: 0.74 - ETA: 0s - loss: 3.8976 - accuracy: 0.74 - ETA: 0s - loss: 3.9088 - accuracy: 0.74 - ETA: 0s - loss: 3.9425 - accuracy: 0.74 - ETA: 0s - loss: 4.0158 - accuracy: 0.73 - ETA: 0s - loss: 4.0342 - accuracy: 0.73 - ETA: 0s - loss: 4.0558 - accuracy: 0.73 - ETA: 0s - loss: 4.0747 - accuracy: 0.73 - ETA: 0s - loss: 4.0759 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 6.1700 - accuracy: 0.60 - ETA: 0s - loss: 3.7751 - accuracy: 0.75 - ETA: 0s - loss: 4.1207 - accuracy: 0.73 - ETA: 0s - loss: 4.0986 - accuracy: 0.73 - ETA: 0s - loss: 4.0726 - accuracy: 0.73 - ETA: 0s - loss: 4.2092 - accuracy: 0.72 - ETA: 0s - loss: 4.1755 - accuracy: 0.72 - ETA: 0s - loss: 4.0849 - accuracy: 0.73 - ETA: 0s - loss: 4.1006 - accuracy: 0.73 - ETA: 0s - loss: 4.0666 - accuracy: 0.73 - ETA: 0s - loss: 4.1162 - accuracy: 0.73 - ETA: 0s - loss: 4.0736 - accuracy: 0.73 - ETA: 0s - loss: 4.0739 - accuracy: 0.73 - ETA: 0s - loss: 4.0780 - accuracy: 0.73 - ETA: 0s - loss: 4.0745 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - ETA: 0s - loss: 10.7975 - accuracy: 0.300 - ETA: 0s - loss: 3.5992 - accuracy: 0.766 - ETA: 0s - loss: 3.8156 - accuracy: 0.75 - ETA: 0s - loss: 3.8030 - accuracy: 0.75 - ETA: 0s - loss: 3.9408 - accuracy: 0.74 - ETA: 0s - loss: 4.0348 - accuracy: 0.73 - ETA: 0s - loss: 4.0254 - accuracy: 0.73 - ETA: 0s - loss: 4.0315 - accuracy: 0.73 - ETA: 0s - loss: 3.9745 - accuracy: 0.74 - ETA: 0s - loss: 3.9855 - accuracy: 0.74 - ETA: 0s - loss: 4.0232 - accuracy: 0.73 - ETA: 0s - loss: 4.0321 - accuracy: 0.73 - ETA: 0s - loss: 4.0262 - accuracy: 0.73 - ETA: 0s - loss: 4.0211 - accuracy: 0.73 - ETA: 0s - loss: 4.0433 - accuracy: 0.73 - 1s 2ms/step - loss: 4.0592 - accuracy: 0.7368 - val_loss: 4.1957 - val_accuracy: 0.7280\n"
     ]
    }
   ],
   "source": [
    "model_object2 = model_2.fit(x=X_train_scaled, \n",
    "          y=y_train, \n",
    "          epochs=100, \n",
    "          batch_size=10,                  \n",
    "          validation_data=(X_test_scaled, y_test),\n",
    "          callbacks=[stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model2,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='./tuner',\n",
    "    project_name='hyperpar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.1607 - accuracy: 0.34 - ETA: 0s - loss: 0.6536 - accuracy: 0.57 - ETA: 0s - loss: 0.5686 - accuracy: 0.58 - ETA: 0s - loss: 0.5392 - accuracy: 0.57 - ETA: 0s - loss: 0.5304 - accuracy: 0.57 - ETA: 0s - loss: 0.5330 - accuracy: 0.57 - 0s 3ms/step - loss: 0.5209 - accuracy: 0.5613 - val_loss: 0.4459 - val_accuracy: 0.6434\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.56 - ETA: 0s - loss: 0.4866 - accuracy: 0.62 - ETA: 0s - loss: 0.5059 - accuracy: 0.56 - ETA: 0s - loss: 0.4975 - accuracy: 0.57 - ETA: 0s - loss: 0.4926 - accuracy: 0.57 - ETA: 0s - loss: 0.4845 - accuracy: 0.58 - 0s 2ms/step - loss: 0.4829 - accuracy: 0.5831 - val_loss: 0.4434 - val_accuracy: 0.6099\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.53 - ETA: 0s - loss: 0.4544 - accuracy: 0.57 - ETA: 0s - loss: 0.4682 - accuracy: 0.60 - ETA: 0s - loss: 0.4672 - accuracy: 0.63 - ETA: 0s - loss: 0.4599 - accuracy: 0.64 - ETA: 0s - loss: 0.4658 - accuracy: 0.64 - 0s 2ms/step - loss: 0.4665 - accuracy: 0.6426 - val_loss: 0.4433 - val_accuracy: 0.7070\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.59 - ETA: 0s - loss: 0.4582 - accuracy: 0.62 - ETA: 0s - loss: 0.4707 - accuracy: 0.65 - ETA: 0s - loss: 0.4759 - accuracy: 0.63 - ETA: 0s - loss: 0.4719 - accuracy: 0.63 - ETA: 0s - loss: 0.4754 - accuracy: 0.62 - 0s 2ms/step - loss: 0.4718 - accuracy: 0.6191 - val_loss: 0.4547 - val_accuracy: 0.6496\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.62 - ETA: 0s - loss: 0.4552 - accuracy: 0.61 - ETA: 0s - loss: 0.4521 - accuracy: 0.60 - ETA: 0s - loss: 0.4590 - accuracy: 0.61 - ETA: 0s - loss: 0.4596 - accuracy: 0.61 - ETA: 0s - loss: 0.4630 - accuracy: 0.61 - 0s 2ms/step - loss: 0.4623 - accuracy: 0.6197 - val_loss: 0.4819 - val_accuracy: 0.6633\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.68 - ETA: 0s - loss: 0.4627 - accuracy: 0.55 - ETA: 0s - loss: 0.4658 - accuracy: 0.56 - ETA: 0s - loss: 0.4627 - accuracy: 0.53 - ETA: 0s - loss: 0.4588 - accuracy: 0.51 - ETA: 0s - loss: 0.4629 - accuracy: 0.52 - 0s 2ms/step - loss: 0.4669 - accuracy: 0.5331 - val_loss: 0.4510 - val_accuracy: 0.6564\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.50 - ETA: 0s - loss: 0.4782 - accuracy: 0.57 - ETA: 0s - loss: 0.4747 - accuracy: 0.58 - ETA: 0s - loss: 0.4624 - accuracy: 0.58 - ETA: 0s - loss: 0.4614 - accuracy: 0.59 - ETA: 0s - loss: 0.4645 - accuracy: 0.60 - 0s 2ms/step - loss: 0.4648 - accuracy: 0.6028 - val_loss: 0.4290 - val_accuracy: 0.6803\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.40 - ETA: 0s - loss: 0.4242 - accuracy: 0.63 - ETA: 0s - loss: 0.4317 - accuracy: 0.62 - ETA: 0s - loss: 0.4329 - accuracy: 0.63 - ETA: 0s - loss: 0.4462 - accuracy: 0.62 - ETA: 0s - loss: 0.4525 - accuracy: 0.61 - 0s 2ms/step - loss: 0.4539 - accuracy: 0.6102 - val_loss: 0.4223 - val_accuracy: 0.5468\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.59 - ETA: 0s - loss: 0.4521 - accuracy: 0.56 - ETA: 0s - loss: 0.4590 - accuracy: 0.55 - ETA: 0s - loss: 0.4496 - accuracy: 0.54 - ETA: 0s - loss: 0.4478 - accuracy: 0.54 - ETA: 0s - loss: 0.4462 - accuracy: 0.53 - ETA: 0s - loss: 0.4439 - accuracy: 0.52 - 0s 2ms/step - loss: 0.4438 - accuracy: 0.5240 - val_loss: 0.4398 - val_accuracy: 0.4889\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.50 - ETA: 0s - loss: 0.4290 - accuracy: 0.52 - ETA: 0s - loss: 0.4399 - accuracy: 0.50 - ETA: 0s - loss: 0.4387 - accuracy: 0.50 - ETA: 0s - loss: 0.4377 - accuracy: 0.49 - ETA: 0s - loss: 0.4433 - accuracy: 0.49 - 0s 2ms/step - loss: 0.4389 - accuracy: 0.4953 - val_loss: 0.4445 - val_accuracy: 0.4566\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.7142 - accuracy: 0.75 - ETA: 0s - loss: 2.1972 - accuracy: 0.69 - ETA: 0s - loss: 2.1727 - accuracy: 0.68 - ETA: 0s - loss: 1.9869 - accuracy: 0.64 - ETA: 0s - loss: 1.7142 - accuracy: 0.60 - ETA: 0s - loss: 1.4977 - accuracy: 0.57 - ETA: 0s - loss: 1.3384 - accuracy: 0.55 - ETA: 0s - loss: 1.2150 - accuracy: 0.54 - 0s 3ms/step - loss: 1.2111 - accuracy: 0.5445 - val_loss: 0.4555 - val_accuracy: 0.5412\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.43 - ETA: 0s - loss: 0.5411 - accuracy: 0.47 - ETA: 0s - loss: 0.5267 - accuracy: 0.43 - ETA: 0s - loss: 0.5212 - accuracy: 0.43 - ETA: 0s - loss: 0.5111 - accuracy: 0.42 - ETA: 0s - loss: 0.5060 - accuracy: 0.40 - ETA: 0s - loss: 0.5088 - accuracy: 0.39 - 0s 2ms/step - loss: 0.5088 - accuracy: 0.3927 - val_loss: 0.4424 - val_accuracy: 0.2970\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.28 - ETA: 0s - loss: 0.4463 - accuracy: 0.33 - ETA: 0s - loss: 0.4663 - accuracy: 0.35 - ETA: 0s - loss: 0.4714 - accuracy: 0.35 - ETA: 0s - loss: 0.4762 - accuracy: 0.35 - ETA: 0s - loss: 0.4798 - accuracy: 0.35 - 0s 2ms/step - loss: 0.4746 - accuracy: 0.3584 - val_loss: 0.4295 - val_accuracy: 0.2737\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.31 - ETA: 0s - loss: 0.4587 - accuracy: 0.37 - ETA: 0s - loss: 0.4626 - accuracy: 0.36 - ETA: 0s - loss: 0.4564 - accuracy: 0.37 - ETA: 0s - loss: 0.4677 - accuracy: 0.37 - ETA: 0s - loss: 0.4667 - accuracy: 0.37 - 0s 2ms/step - loss: 0.4657 - accuracy: 0.3802 - val_loss: 0.4252 - val_accuracy: 0.3049\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.43 - ETA: 0s - loss: 0.4541 - accuracy: 0.42 - ETA: 0s - loss: 0.4503 - accuracy: 0.41 - ETA: 0s - loss: 0.4585 - accuracy: 0.48 - ETA: 0s - loss: 0.4576 - accuracy: 0.51 - ETA: 0s - loss: 0.4594 - accuracy: 0.53 - 0s 2ms/step - loss: 0.4628 - accuracy: 0.5371 - val_loss: 0.4273 - val_accuracy: 0.6417\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.65 - ETA: 0s - loss: 0.4765 - accuracy: 0.62 - ETA: 0s - loss: 0.4680 - accuracy: 0.52 - ETA: 0s - loss: 0.4652 - accuracy: 0.56 - ETA: 0s - loss: 0.4622 - accuracy: 0.59 - ETA: 0s - loss: 0.4640 - accuracy: 0.59 - 0s 2ms/step - loss: 0.4618 - accuracy: 0.5924 - val_loss: 0.4373 - val_accuracy: 0.5917\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.53 - ETA: 0s - loss: 0.4095 - accuracy: 0.64 - ETA: 0s - loss: 0.4384 - accuracy: 0.67 - ETA: 0s - loss: 0.4444 - accuracy: 0.67 - ETA: 0s - loss: 0.4442 - accuracy: 0.65 - ETA: 0s - loss: 0.4514 - accuracy: 0.65 - 0s 2ms/step - loss: 0.4547 - accuracy: 0.6518 - val_loss: 0.4331 - val_accuracy: 0.6178\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.65 - ETA: 0s - loss: 0.4999 - accuracy: 0.61 - ETA: 0s - loss: 0.4812 - accuracy: 0.48 - ETA: 0s - loss: 0.4628 - accuracy: 0.51 - ETA: 0s - loss: 0.4597 - accuracy: 0.54 - ETA: 0s - loss: 0.4552 - accuracy: 0.53 - 0s 2ms/step - loss: 0.4572 - accuracy: 0.5447 - val_loss: 0.4320 - val_accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.84 - ETA: 0s - loss: 0.4178 - accuracy: 0.68 - ETA: 0s - loss: 0.4354 - accuracy: 0.66 - ETA: 0s - loss: 0.4309 - accuracy: 0.66 - ETA: 0s - loss: 0.4411 - accuracy: 0.67 - ETA: 0s - loss: 0.4461 - accuracy: 0.67 - 0s 2ms/step - loss: 0.4460 - accuracy: 0.6734 - val_loss: 0.4275 - val_accuracy: 0.7110\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.62 - ETA: 0s - loss: 0.4275 - accuracy: 0.64 - ETA: 0s - loss: 0.4439 - accuracy: 0.66 - ETA: 0s - loss: 0.4393 - accuracy: 0.66 - ETA: 0s - loss: 0.4360 - accuracy: 0.67 - ETA: 0s - loss: 0.4508 - accuracy: 0.66 - 0s 2ms/step - loss: 0.4498 - accuracy: 0.6674 - val_loss: 0.4338 - val_accuracy: 0.6496\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.62 - ETA: 0s - loss: 0.6555 - accuracy: 0.44 - ETA: 0s - loss: 0.6071 - accuracy: 0.46 - ETA: 0s - loss: 0.5784 - accuracy: 0.45 - ETA: 0s - loss: 0.5696 - accuracy: 0.46 - ETA: 0s - loss: 0.5595 - accuracy: 0.46 - ETA: 0s - loss: 0.5502 - accuracy: 0.47 - 0s 3ms/step - loss: 0.5498 - accuracy: 0.4849 - val_loss: 0.4322 - val_accuracy: 0.6837\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.62 - ETA: 0s - loss: 0.4822 - accuracy: 0.60 - ETA: 0s - loss: 0.4885 - accuracy: 0.58 - ETA: 0s - loss: 0.4788 - accuracy: 0.54 - ETA: 0s - loss: 0.4813 - accuracy: 0.55 - ETA: 0s - loss: 0.4836 - accuracy: 0.55 - 0s 2ms/step - loss: 0.4887 - accuracy: 0.5562 - val_loss: 0.4354 - val_accuracy: 0.4946\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.28 - ETA: 0s - loss: 0.4495 - accuracy: 0.49 - ETA: 0s - loss: 0.4649 - accuracy: 0.47 - ETA: 0s - loss: 0.4697 - accuracy: 0.49 - ETA: 0s - loss: 0.4761 - accuracy: 0.49 - ETA: 0s - loss: 0.4824 - accuracy: 0.50 - 0s 2ms/step - loss: 0.4815 - accuracy: 0.5049 - val_loss: 0.4519 - val_accuracy: 0.5014\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.62 - ETA: 0s - loss: 0.5121 - accuracy: 0.49 - ETA: 0s - loss: 0.4804 - accuracy: 0.44 - ETA: 0s - loss: 0.4795 - accuracy: 0.50 - ETA: 0s - loss: 0.4798 - accuracy: 0.53 - ETA: 0s - loss: 0.4777 - accuracy: 0.53 - 0s 2ms/step - loss: 0.4790 - accuracy: 0.5310 - val_loss: 0.4260 - val_accuracy: 0.4509\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.50 - ETA: 0s - loss: 0.4568 - accuracy: 0.49 - ETA: 0s - loss: 0.4620 - accuracy: 0.48 - ETA: 0s - loss: 0.4664 - accuracy: 0.50 - ETA: 0s - loss: 0.4722 - accuracy: 0.51 - ETA: 0s - loss: 0.4668 - accuracy: 0.50 - 0s 2ms/step - loss: 0.4679 - accuracy: 0.5049 - val_loss: 0.4477 - val_accuracy: 0.4384\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.43 - ETA: 0s - loss: 0.4373 - accuracy: 0.43 - ETA: 0s - loss: 0.4385 - accuracy: 0.43 - ETA: 0s - loss: 0.4465 - accuracy: 0.44 - ETA: 0s - loss: 0.4463 - accuracy: 0.45 - ETA: 0s - loss: 0.4481 - accuracy: 0.45 - 0s 2ms/step - loss: 0.4508 - accuracy: 0.4563 - val_loss: 0.4309 - val_accuracy: 0.4441\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.34 - ETA: 0s - loss: 0.4478 - accuracy: 0.49 - ETA: 0s - loss: 0.4466 - accuracy: 0.52 - ETA: 0s - loss: 0.4564 - accuracy: 0.52 - ETA: 0s - loss: 0.4572 - accuracy: 0.50 - ETA: 0s - loss: 0.4575 - accuracy: 0.50 - 0s 2ms/step - loss: 0.4551 - accuracy: 0.5019 - val_loss: 0.4318 - val_accuracy: 0.4168\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.37 - ETA: 0s - loss: 0.4292 - accuracy: 0.42 - ETA: 0s - loss: 0.4157 - accuracy: 0.45 - ETA: 0s - loss: 0.4425 - accuracy: 0.45 - ETA: 0s - loss: 0.4442 - accuracy: 0.46 - ETA: 0s - loss: 0.4570 - accuracy: 0.48 - 0s 2ms/step - loss: 0.4629 - accuracy: 0.4932 - val_loss: 0.4517 - val_accuracy: 0.5344\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.53 - ETA: 0s - loss: 0.4533 - accuracy: 0.56 - ETA: 0s - loss: 0.4418 - accuracy: 0.55 - ETA: 0s - loss: 0.4284 - accuracy: 0.55 - ETA: 0s - loss: 0.4476 - accuracy: 0.54 - ETA: 0s - loss: 0.4501 - accuracy: 0.54 - 0s 2ms/step - loss: 0.4530 - accuracy: 0.5418 - val_loss: 0.4261 - val_accuracy: 0.4787\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.50 - ETA: 0s - loss: 0.4608 - accuracy: 0.49 - ETA: 0s - loss: 0.4463 - accuracy: 0.48 - ETA: 0s - loss: 0.4493 - accuracy: 0.46 - ETA: 0s - loss: 0.4435 - accuracy: 0.46 - 0s 2ms/step - loss: 0.4429 - accuracy: 0.4699 - val_loss: 0.4372 - val_accuracy: 0.4321\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: eb796609627ab57c14431dfdc7517679</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7005489269892374</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 480</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.9444 - accuracy: 0.71 - ETA: 0s - loss: 1.6389 - accuracy: 0.70 - ETA: 0s - loss: 1.4746 - accuracy: 0.70 - ETA: 0s - loss: 1.3085 - accuracy: 0.70 - ETA: 0s - loss: 1.1781 - accuracy: 0.70 - ETA: 0s - loss: 1.1073 - accuracy: 0.70 - ETA: 0s - loss: 1.0419 - accuracy: 0.69 - 0s 3ms/step - loss: 1.0121 - accuracy: 0.6982 - val_loss: 0.5883 - val_accuracy: 0.7206\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.8760 - accuracy: 0.65 - ETA: 0s - loss: 0.7986 - accuracy: 0.68 - ETA: 0s - loss: 0.7682 - accuracy: 0.68 - ETA: 0s - loss: 0.7568 - accuracy: 0.67 - ETA: 0s - loss: 0.7589 - accuracy: 0.66 - ETA: 0s - loss: 0.7305 - accuracy: 0.66 - 0s 2ms/step - loss: 0.7298 - accuracy: 0.6672 - val_loss: 0.5252 - val_accuracy: 0.6604\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.68 - ETA: 0s - loss: 0.6989 - accuracy: 0.64 - ETA: 0s - loss: 0.6655 - accuracy: 0.63 - ETA: 0s - loss: 0.6485 - accuracy: 0.63 - ETA: 0s - loss: 0.6517 - accuracy: 0.62 - ETA: 0s - loss: 0.6342 - accuracy: 0.62 - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6210 - val_loss: 0.4845 - val_accuracy: 0.6326\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.65 - ETA: 0s - loss: 0.5683 - accuracy: 0.64 - ETA: 0s - loss: 0.5554 - accuracy: 0.61 - ETA: 0s - loss: 0.5638 - accuracy: 0.60 - ETA: 0s - loss: 0.5617 - accuracy: 0.60 - ETA: 0s - loss: 0.5678 - accuracy: 0.59 - 0s 2ms/step - loss: 0.5668 - accuracy: 0.5964 - val_loss: 0.4674 - val_accuracy: 0.5792\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.53 - ETA: 0s - loss: 0.5679 - accuracy: 0.57 - ETA: 0s - loss: 0.5397 - accuracy: 0.57 - ETA: 0s - loss: 0.5388 - accuracy: 0.57 - ETA: 0s - loss: 0.5308 - accuracy: 0.57 - ETA: 0s - loss: 0.5368 - accuracy: 0.57 - 0s 2ms/step - loss: 0.5366 - accuracy: 0.5740 - val_loss: 0.4577 - val_accuracy: 0.5423\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.56 - ETA: 0s - loss: 0.5029 - accuracy: 0.56 - ETA: 0s - loss: 0.5235 - accuracy: 0.57 - ETA: 0s - loss: 0.5310 - accuracy: 0.57 - ETA: 0s - loss: 0.5225 - accuracy: 0.56 - 0s 2ms/step - loss: 0.5263 - accuracy: 0.5636 - val_loss: 0.4494 - val_accuracy: 0.5514\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.68 - ETA: 0s - loss: 0.5100 - accuracy: 0.57 - ETA: 0s - loss: 0.5355 - accuracy: 0.55 - ETA: 0s - loss: 0.5251 - accuracy: 0.56 - ETA: 0s - loss: 0.5204 - accuracy: 0.56 - ETA: 0s - loss: 0.5229 - accuracy: 0.56 - 0s 2ms/step - loss: 0.5216 - accuracy: 0.5659 - val_loss: 0.4436 - val_accuracy: 0.5230\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.59 - ETA: 0s - loss: 0.4939 - accuracy: 0.53 - ETA: 0s - loss: 0.5061 - accuracy: 0.54 - ETA: 0s - loss: 0.5105 - accuracy: 0.54 - ETA: 0s - loss: 0.5065 - accuracy: 0.54 - 0s 2ms/step - loss: 0.5088 - accuracy: 0.5498 - val_loss: 0.4467 - val_accuracy: 0.5168\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.68 - ETA: 0s - loss: 0.4742 - accuracy: 0.55 - ETA: 0s - loss: 0.5045 - accuracy: 0.55 - ETA: 0s - loss: 0.5018 - accuracy: 0.55 - ETA: 0s - loss: 0.5005 - accuracy: 0.54 - 0s 2ms/step - loss: 0.4966 - accuracy: 0.5441 - val_loss: 0.4441 - val_accuracy: 0.5434\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.53 - ETA: 0s - loss: 0.4874 - accuracy: 0.54 - ETA: 0s - loss: 0.4838 - accuracy: 0.54 - ETA: 0s - loss: 0.4933 - accuracy: 0.55 - ETA: 0s - loss: 0.4939 - accuracy: 0.54 - 0s 2ms/step - loss: 0.4968 - accuracy: 0.5515 - val_loss: 0.4371 - val_accuracy: 0.5491\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.3392 - accuracy: 0.78 - ETA: 0s - loss: 2.6007 - accuracy: 0.73 - ETA: 0s - loss: 2.4708 - accuracy: 0.73 - ETA: 0s - loss: 2.4819 - accuracy: 0.72 - ETA: 0s - loss: 2.4796 - accuracy: 0.72 - ETA: 0s - loss: 2.4783 - accuracy: 0.72 - ETA: 0s - loss: 2.4342 - accuracy: 0.71 - 0s 3ms/step - loss: 2.4237 - accuracy: 0.7168 - val_loss: 2.1655 - val_accuracy: 0.7229\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.7594 - accuracy: 0.68 - ETA: 0s - loss: 2.0917 - accuracy: 0.70 - ETA: 0s - loss: 2.1213 - accuracy: 0.67 - ETA: 0s - loss: 2.0238 - accuracy: 0.68 - ETA: 0s - loss: 1.9027 - accuracy: 0.67 - ETA: 0s - loss: 1.8412 - accuracy: 0.66 - 0s 2ms/step - loss: 1.8137 - accuracy: 0.6640 - val_loss: 1.1031 - val_accuracy: 0.6394\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.1444 - accuracy: 0.56 - ETA: 0s - loss: 1.5563 - accuracy: 0.60 - ETA: 0s - loss: 1.5198 - accuracy: 0.60 - ETA: 0s - loss: 1.4361 - accuracy: 0.59 - ETA: 0s - loss: 1.3927 - accuracy: 0.59 - ETA: 0s - loss: 1.3497 - accuracy: 0.59 - 0s 2ms/step - loss: 1.3485 - accuracy: 0.5930 - val_loss: 0.7707 - val_accuracy: 0.5821\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.1637 - accuracy: 0.71 - ETA: 0s - loss: 1.3826 - accuracy: 0.60 - ETA: 0s - loss: 1.2257 - accuracy: 0.61 - ETA: 0s - loss: 1.1307 - accuracy: 0.60 - ETA: 0s - loss: 1.1399 - accuracy: 0.59 - ETA: 0s - loss: 1.1452 - accuracy: 0.58 - 0s 2ms/step - loss: 1.1443 - accuracy: 0.5875 - val_loss: 0.7181 - val_accuracy: 0.5679\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.9591 - accuracy: 0.62 - ETA: 0s - loss: 1.0469 - accuracy: 0.58 - ETA: 0s - loss: 1.0703 - accuracy: 0.58 - ETA: 0s - loss: 1.0996 - accuracy: 0.58 - ETA: 0s - loss: 1.0961 - accuracy: 0.57 - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5714 - val_loss: 0.6830 - val_accuracy: 0.5258\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.8765 - accuracy: 0.46 - ETA: 0s - loss: 1.0471 - accuracy: 0.55 - ETA: 0s - loss: 1.0129 - accuracy: 0.56 - ETA: 0s - loss: 0.9941 - accuracy: 0.57 - ETA: 0s - loss: 0.9793 - accuracy: 0.58 - ETA: 0s - loss: 0.9816 - accuracy: 0.58 - 0s 2ms/step - loss: 0.9730 - accuracy: 0.5867 - val_loss: 0.6487 - val_accuracy: 0.6150\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.75 - ETA: 0s - loss: 0.9152 - accuracy: 0.60 - ETA: 0s - loss: 0.8965 - accuracy: 0.62 - ETA: 0s - loss: 0.9203 - accuracy: 0.62 - ETA: 0s - loss: 0.9247 - accuracy: 0.62 - ETA: 0s - loss: 0.9312 - accuracy: 0.62 - 0s 2ms/step - loss: 0.9249 - accuracy: 0.6227 - val_loss: 0.6466 - val_accuracy: 0.6718\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.53 - ETA: 0s - loss: 0.8616 - accuracy: 0.65 - ETA: 0s - loss: 0.8492 - accuracy: 0.63 - ETA: 0s - loss: 0.8891 - accuracy: 0.62 - ETA: 0s - loss: 0.8863 - accuracy: 0.61 - 0s 2ms/step - loss: 0.8827 - accuracy: 0.6185 - val_loss: 0.6204 - val_accuracy: 0.6383\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.0573 - accuracy: 0.68 - ETA: 0s - loss: 0.8320 - accuracy: 0.60 - ETA: 0s - loss: 0.8594 - accuracy: 0.60 - ETA: 0s - loss: 0.9061 - accuracy: 0.60 - ETA: 0s - loss: 0.8767 - accuracy: 0.61 - ETA: 0s - loss: 0.8587 - accuracy: 0.61 - 0s 2ms/step - loss: 0.8651 - accuracy: 0.6104 - val_loss: 0.5986 - val_accuracy: 0.6400\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.8103 - accuracy: 0.50 - ETA: 0s - loss: 0.8310 - accuracy: 0.58 - ETA: 0s - loss: 0.8210 - accuracy: 0.59 - ETA: 0s - loss: 0.8259 - accuracy: 0.60 - ETA: 0s - loss: 0.8311 - accuracy: 0.60 - 0s 2ms/step - loss: 0.8348 - accuracy: 0.6149 - val_loss: 0.5744 - val_accuracy: 0.6275\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.6123 - accuracy: 0.78 - ETA: 0s - loss: 2.1011 - accuracy: 0.73 - ETA: 0s - loss: 2.1337 - accuracy: 0.71 - ETA: 0s - loss: 2.0324 - accuracy: 0.71 - ETA: 0s - loss: 1.9280 - accuracy: 0.70 - ETA: 0s - loss: 1.8160 - accuracy: 0.70 - ETA: 0s - loss: 1.7073 - accuracy: 0.69 - 0s 3ms/step - loss: 1.6896 - accuracy: 0.6929 - val_loss: 0.6677 - val_accuracy: 0.6740\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.0301 - accuracy: 0.62 - ETA: 0s - loss: 1.0183 - accuracy: 0.67 - ETA: 0s - loss: 0.9907 - accuracy: 0.66 - ETA: 0s - loss: 0.9742 - accuracy: 0.67 - ETA: 0s - loss: 0.9520 - accuracy: 0.65 - ETA: 0s - loss: 0.9564 - accuracy: 0.65 - 0s 2ms/step - loss: 0.9561 - accuracy: 0.6564 - val_loss: 0.5536 - val_accuracy: 0.6655\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.78 - ETA: 0s - loss: 0.7628 - accuracy: 0.67 - ETA: 0s - loss: 0.8017 - accuracy: 0.66 - ETA: 0s - loss: 0.8255 - accuracy: 0.66 - ETA: 0s - loss: 0.8123 - accuracy: 0.67 - ETA: 0s - loss: 0.7971 - accuracy: 0.67 - 0s 2ms/step - loss: 0.7921 - accuracy: 0.6681 - val_loss: 0.5214 - val_accuracy: 0.6786\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.59 - ETA: 0s - loss: 0.6975 - accuracy: 0.66 - ETA: 0s - loss: 0.7524 - accuracy: 0.65 - ETA: 0s - loss: 0.7180 - accuracy: 0.65 - ETA: 0s - loss: 0.7241 - accuracy: 0.65 - ETA: 0s - loss: 0.7294 - accuracy: 0.66 - 0s 2ms/step - loss: 0.7327 - accuracy: 0.6571 - val_loss: 0.5054 - val_accuracy: 0.6599\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.53 - ETA: 0s - loss: 0.6762 - accuracy: 0.66 - ETA: 0s - loss: 0.6848 - accuracy: 0.66 - ETA: 0s - loss: 0.6874 - accuracy: 0.67 - ETA: 0s - loss: 0.6942 - accuracy: 0.66 - ETA: 0s - loss: 0.7152 - accuracy: 0.66 - 0s 2ms/step - loss: 0.7122 - accuracy: 0.6621 - val_loss: 0.4858 - val_accuracy: 0.6479\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7882 - accuracy: 0.59 - ETA: 0s - loss: 0.8145 - accuracy: 0.63 - ETA: 0s - loss: 0.7173 - accuracy: 0.64 - ETA: 0s - loss: 0.7022 - accuracy: 0.64 - ETA: 0s - loss: 0.6847 - accuracy: 0.64 - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6448 - val_loss: 0.4793 - val_accuracy: 0.6417\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.46 - ETA: 0s - loss: 0.7858 - accuracy: 0.63 - ETA: 0s - loss: 0.6910 - accuracy: 0.65 - ETA: 0s - loss: 0.7013 - accuracy: 0.64 - ETA: 0s - loss: 0.7021 - accuracy: 0.65 - 0s 2ms/step - loss: 0.7031 - accuracy: 0.6564 - val_loss: 0.4690 - val_accuracy: 0.6689\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.68 - ETA: 0s - loss: 0.6979 - accuracy: 0.66 - ETA: 0s - loss: 0.7004 - accuracy: 0.67 - ETA: 0s - loss: 0.6803 - accuracy: 0.66 - ETA: 0s - loss: 0.6673 - accuracy: 0.65 - ETA: 0s - loss: 0.6653 - accuracy: 0.66 - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6615 - val_loss: 0.4624 - val_accuracy: 0.6661\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.1019 - accuracy: 0.62 - ETA: 0s - loss: 0.7334 - accuracy: 0.68 - ETA: 0s - loss: 0.7171 - accuracy: 0.68 - ETA: 0s - loss: 0.7102 - accuracy: 0.67 - ETA: 0s - loss: 0.6796 - accuracy: 0.67 - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6725 - val_loss: 0.4535 - val_accuracy: 0.6814\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.8280 - accuracy: 0.59 - ETA: 0s - loss: 0.6125 - accuracy: 0.67 - ETA: 0s - loss: 0.6383 - accuracy: 0.67 - ETA: 0s - loss: 0.6585 - accuracy: 0.66 - ETA: 0s - loss: 0.6456 - accuracy: 0.67 - ETA: 0s - loss: 0.6642 - accuracy: 0.66 - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6715 - val_loss: 0.4448 - val_accuracy: 0.6780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 14165ec167e47c62010e9d2a6f6ad3fd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7083096702893575</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.0540 - accuracy: 0.65 - ETA: 0s - loss: 3.5344 - accuracy: 0.47 - ETA: 0s - loss: 3.2649 - accuracy: 0.52 - ETA: 0s - loss: 3.2134 - accuracy: 0.55 - ETA: 0s - loss: 3.1585 - accuracy: 0.57 - ETA: 0s - loss: 2.9454 - accuracy: 0.57 - 0s 3ms/step - loss: 2.7560 - accuracy: 0.5670 - val_loss: 0.6668 - val_accuracy: 0.5156\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.46 - ETA: 0s - loss: 0.7760 - accuracy: 0.58 - ETA: 0s - loss: 0.8140 - accuracy: 0.61 - ETA: 0s - loss: 0.7994 - accuracy: 0.59 - ETA: 0s - loss: 0.8216 - accuracy: 0.59 - ETA: 0s - loss: 0.8125 - accuracy: 0.61 - 0s 2ms/step - loss: 0.7968 - accuracy: 0.6189 - val_loss: 0.5754 - val_accuracy: 0.6616\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.62 - ETA: 0s - loss: 0.5642 - accuracy: 0.61 - ETA: 0s - loss: 0.5913 - accuracy: 0.61 - ETA: 0s - loss: 0.6128 - accuracy: 0.60 - ETA: 0s - loss: 0.6143 - accuracy: 0.55 - ETA: 0s - loss: 0.6094 - accuracy: 0.52 - 0s 2ms/step - loss: 0.6070 - accuracy: 0.5195 - val_loss: 0.5557 - val_accuracy: 0.5292\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7074 - accuracy: 0.62 - ETA: 0s - loss: 0.5872 - accuracy: 0.45 - ETA: 0s - loss: 0.6092 - accuracy: 0.45 - ETA: 0s - loss: 0.5990 - accuracy: 0.45 - ETA: 0s - loss: 0.5823 - accuracy: 0.45 - ETA: 0s - loss: 0.5767 - accuracy: 0.44 - 0s 2ms/step - loss: 0.5738 - accuracy: 0.4271 - val_loss: 0.5092 - val_accuracy: 0.2942\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.31 - ETA: 0s - loss: 0.5023 - accuracy: 0.33 - ETA: 0s - loss: 0.5487 - accuracy: 0.39 - ETA: 0s - loss: 0.5762 - accuracy: 0.43 - ETA: 0s - loss: 0.5871 - accuracy: 0.46 - ETA: 0s - loss: 0.5800 - accuracy: 0.51 - 0s 2ms/step - loss: 0.5787 - accuracy: 0.5276 - val_loss: 0.6046 - val_accuracy: 0.6865\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.62 - ETA: 0s - loss: 0.7631 - accuracy: 0.65 - ETA: 0s - loss: 0.6601 - accuracy: 0.55 - ETA: 0s - loss: 0.6252 - accuracy: 0.49 - ETA: 0s - loss: 0.5963 - accuracy: 0.44 - ETA: 0s - loss: 0.5805 - accuracy: 0.41 - 0s 2ms/step - loss: 0.5786 - accuracy: 0.4140 - val_loss: 0.4924 - val_accuracy: 0.2641\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.28 - ETA: 0s - loss: 0.4925 - accuracy: 0.28 - ETA: 0s - loss: 0.5146 - accuracy: 0.28 - ETA: 0s - loss: 0.5139 - accuracy: 0.28 - ETA: 0s - loss: 0.5178 - accuracy: 0.28 - ETA: 0s - loss: 0.5248 - accuracy: 0.35 - 0s 2ms/step - loss: 0.5244 - accuracy: 0.3728 - val_loss: 0.5283 - val_accuracy: 0.6122\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.56 - ETA: 0s - loss: 0.5389 - accuracy: 0.39 - ETA: 0s - loss: 0.5143 - accuracy: 0.33 - ETA: 0s - loss: 0.5062 - accuracy: 0.32 - ETA: 0s - loss: 0.4978 - accuracy: 0.30 - ETA: 0s - loss: 0.4951 - accuracy: 0.30 - 0s 2ms/step - loss: 0.4963 - accuracy: 0.3243 - val_loss: 0.4511 - val_accuracy: 0.7280\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.65 - ETA: 0s - loss: 0.4855 - accuracy: 0.43 - ETA: 0s - loss: 0.4786 - accuracy: 0.38 - ETA: 0s - loss: 0.4906 - accuracy: 0.38 - ETA: 0s - loss: 0.5157 - accuracy: 0.42 - ETA: 0s - loss: 0.5128 - accuracy: 0.39 - 0s 2ms/step - loss: 0.5126 - accuracy: 0.3957 - val_loss: 0.4483 - val_accuracy: 0.2527\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.31 - ETA: 0s - loss: 0.4920 - accuracy: 0.45 - ETA: 0s - loss: 0.4831 - accuracy: 0.53 - ETA: 0s - loss: 0.4785 - accuracy: 0.59 - ETA: 0s - loss: 0.4786 - accuracy: 0.51 - ETA: 0s - loss: 0.4786 - accuracy: 0.50 - 0s 2ms/step - loss: 0.4786 - accuracy: 0.5023 - val_loss: 0.4545 - val_accuracy: 0.7019\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.3774 - accuracy: 0.62 - ETA: 0s - loss: 3.4506 - accuracy: 0.72 - ETA: 0s - loss: 3.2727 - accuracy: 0.72 - ETA: 0s - loss: 2.9084 - accuracy: 0.73 - ETA: 0s - loss: 2.8091 - accuracy: 0.72 - ETA: 0s - loss: 2.7073 - accuracy: 0.73 - 0s 2ms/step - loss: 2.6918 - accuracy: 0.7323 - val_loss: 2.3902 - val_accuracy: 0.7280\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.4295 - accuracy: 0.71 - ETA: 0s - loss: 2.1204 - accuracy: 0.76 - ETA: 0s - loss: 2.2315 - accuracy: 0.75 - ETA: 0s - loss: 2.3014 - accuracy: 0.74 - ETA: 0s - loss: 2.3472 - accuracy: 0.73 - 0s 2ms/step - loss: 2.3575 - accuracy: 0.7367 - val_loss: 2.4178 - val_accuracy: 0.7280\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.8999 - accuracy: 0.68 - ETA: 0s - loss: 2.3557 - accuracy: 0.73 - ETA: 0s - loss: 2.2790 - accuracy: 0.75 - ETA: 0s - loss: 2.3160 - accuracy: 0.74 - ETA: 0s - loss: 2.3155 - accuracy: 0.74 - 0s 2ms/step - loss: 2.3510 - accuracy: 0.7368 - val_loss: 2.3767 - val_accuracy: 0.7280\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.6849 - accuracy: 0.68 - ETA: 0s - loss: 2.4230 - accuracy: 0.72 - ETA: 0s - loss: 2.3430 - accuracy: 0.73 - ETA: 0s - loss: 2.3453 - accuracy: 0.73 - ETA: 0s - loss: 2.3599 - accuracy: 0.73 - 0s 2ms/step - loss: 2.3668 - accuracy: 0.7368 - val_loss: 2.5173 - val_accuracy: 0.7280\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.3818 - accuracy: 0.71 - ETA: 0s - loss: 2.4375 - accuracy: 0.74 - ETA: 0s - loss: 2.5029 - accuracy: 0.73 - ETA: 0s - loss: 2.4762 - accuracy: 0.74 - ETA: 0s - loss: 2.5744 - accuracy: 0.73 - 0s 2ms/step - loss: 2.6058 - accuracy: 0.7367 - val_loss: 2.5930 - val_accuracy: 0.7280\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.8149 - accuracy: 0.78 - ETA: 0s - loss: 2.5139 - accuracy: 0.73 - ETA: 0s - loss: 2.6012 - accuracy: 0.73 - ETA: 0s - loss: 2.6321 - accuracy: 0.73 - ETA: 0s - loss: 2.5680 - accuracy: 0.73 - 0s 2ms/step - loss: 2.5094 - accuracy: 0.7368 - val_loss: 2.3536 - val_accuracy: 0.7280\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.4025 - accuracy: 0.75 - ETA: 0s - loss: 2.1328 - accuracy: 0.76 - ETA: 0s - loss: 2.2407 - accuracy: 0.74 - ETA: 0s - loss: 2.2922 - accuracy: 0.74 - ETA: 0s - loss: 2.3133 - accuracy: 0.73 - 0s 2ms/step - loss: 2.3297 - accuracy: 0.7367 - val_loss: 2.3662 - val_accuracy: 0.7280\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.2052 - accuracy: 0.62 - ETA: 0s - loss: 2.4084 - accuracy: 0.72 - ETA: 0s - loss: 2.3736 - accuracy: 0.73 - ETA: 0s - loss: 2.3489 - accuracy: 0.73 - ETA: 0s - loss: 2.3282 - accuracy: 0.73 - 0s 2ms/step - loss: 2.3372 - accuracy: 0.7370 - val_loss: 2.3882 - val_accuracy: 0.7280\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.8505 - accuracy: 0.65 - ETA: 0s - loss: 2.3057 - accuracy: 0.74 - ETA: 0s - loss: 2.3533 - accuracy: 0.74 - ETA: 0s - loss: 2.3863 - accuracy: 0.73 - ETA: 0s - loss: 2.4357 - accuracy: 0.73 - 0s 2ms/step - loss: 2.4049 - accuracy: 0.7368 - val_loss: 2.4471 - val_accuracy: 0.7280\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.6248 - accuracy: 0.56 - ETA: 0s - loss: 2.5326 - accuracy: 0.72 - ETA: 0s - loss: 2.5141 - accuracy: 0.72 - ETA: 0s - loss: 2.3995 - accuracy: 0.73 - ETA: 0s - loss: 2.6398 - accuracy: 0.73 - 0s 2ms/step - loss: 2.8314 - accuracy: 0.7368 - val_loss: 4.1959 - val_accuracy: 0.7280\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.6671 - accuracy: 0.15 - ETA: 0s - loss: 2.4759 - accuracy: 0.42 - ETA: 0s - loss: 2.5778 - accuracy: 0.44 - ETA: 0s - loss: 2.5330 - accuracy: 0.40 - ETA: 0s - loss: 2.4581 - accuracy: 0.40 - ETA: 0s - loss: 2.4666 - accuracy: 0.41 - ETA: 0s - loss: 2.4141 - accuracy: 0.40 - 0s 3ms/step - loss: 2.4213 - accuracy: 0.4089 - val_loss: 2.3620 - val_accuracy: 0.5122\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.3870 - accuracy: 0.53 - ETA: 0s - loss: 2.3322 - accuracy: 0.38 - ETA: 0s - loss: 2.4183 - accuracy: 0.34 - ETA: 0s - loss: 2.3459 - accuracy: 0.34 - ETA: 0s - loss: 2.3222 - accuracy: 0.38 - ETA: 0s - loss: 2.2986 - accuracy: 0.37 - 0s 2ms/step - loss: 2.3019 - accuracy: 0.3749 - val_loss: 2.3628 - val_accuracy: 0.3844\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.4195 - accuracy: 0.37 - ETA: 0s - loss: 2.2715 - accuracy: 0.42 - ETA: 0s - loss: 2.3481 - accuracy: 0.38 - ETA: 0s - loss: 2.3201 - accuracy: 0.37 - ETA: 0s - loss: 2.3109 - accuracy: 0.36 - ETA: 0s - loss: 2.3334 - accuracy: 0.37 - 0s 2ms/step - loss: 2.3192 - accuracy: 0.3866 - val_loss: 2.4512 - val_accuracy: 0.5860\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.8622 - accuracy: 0.59 - ETA: 0s - loss: 2.4162 - accuracy: 0.50 - ETA: 0s - loss: 2.4094 - accuracy: 0.50 - ETA: 0s - loss: 2.3107 - accuracy: 0.53 - ETA: 0s - loss: 2.3327 - accuracy: 0.52 - ETA: 0s - loss: 2.3536 - accuracy: 0.49 - 0s 2ms/step - loss: 2.3504 - accuracy: 0.4970 - val_loss: 2.3837 - val_accuracy: 0.5588\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.6486 - accuracy: 0.68 - ETA: 0s - loss: 2.5694 - accuracy: 0.46 - ETA: 0s - loss: 2.4356 - accuracy: 0.43 - ETA: 0s - loss: 2.3746 - accuracy: 0.43 - ETA: 0s - loss: 2.3619 - accuracy: 0.39 - ETA: 0s - loss: 2.3531 - accuracy: 0.37 - 0s 2ms/step - loss: 2.3330 - accuracy: 0.3654 - val_loss: 2.3818 - val_accuracy: 0.2720\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.4332 - accuracy: 0.15 - ETA: 0s - loss: 2.3262 - accuracy: 0.26 - ETA: 0s - loss: 2.2277 - accuracy: 0.25 - ETA: 0s - loss: 2.2541 - accuracy: 0.25 - ETA: 0s - loss: 2.2651 - accuracy: 0.26 - ETA: 0s - loss: 2.2931 - accuracy: 0.26 - 0s 2ms/step - loss: 2.2903 - accuracy: 0.2632 - val_loss: 2.3677 - val_accuracy: 0.2720\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 3.5003 - accuracy: 0.40 - ETA: 0s - loss: 2.2848 - accuracy: 0.26 - ETA: 0s - loss: 2.3225 - accuracy: 0.26 - ETA: 0s - loss: 2.3044 - accuracy: 0.26 - ETA: 0s - loss: 2.3045 - accuracy: 0.26 - 0s 2ms/step - loss: 2.2910 - accuracy: 0.2632 - val_loss: 2.3341 - val_accuracy: 0.2720\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.1924 - accuracy: 0.25 - ETA: 0s - loss: 2.1301 - accuracy: 0.24 - ETA: 0s - loss: 2.1891 - accuracy: 0.25 - ETA: 0s - loss: 2.2449 - accuracy: 0.25 - ETA: 0s - loss: 2.2586 - accuracy: 0.25 - 0s 2ms/step - loss: 2.2882 - accuracy: 0.2632 - val_loss: 2.3469 - val_accuracy: 0.2720\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.6637 - accuracy: 0.31 - ETA: 0s - loss: 2.3289 - accuracy: 0.27 - ETA: 0s - loss: 2.2993 - accuracy: 0.26 - ETA: 0s - loss: 2.2833 - accuracy: 0.26 - ETA: 0s - loss: 2.2707 - accuracy: 0.26 - 0s 2ms/step - loss: 2.2782 - accuracy: 0.2632 - val_loss: 2.3307 - val_accuracy: 0.2720\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.9222 - accuracy: 0.21 - ETA: 0s - loss: 2.1460 - accuracy: 0.24 - ETA: 0s - loss: 2.1921 - accuracy: 0.25 - ETA: 0s - loss: 2.2023 - accuracy: 0.25 - ETA: 0s - loss: 2.2427 - accuracy: 0.25 - 0s 2ms/step - loss: 2.2786 - accuracy: 0.2632 - val_loss: 2.3347 - val_accuracy: 0.2720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b78eabf5e408f05d3e158013b0de9cce</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6806738575299581</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.3850 - accuracy: 0.37 - ETA: 0s - loss: 0.8405 - accuracy: 0.52 - ETA: 0s - loss: 0.7327 - accuracy: 0.40 - ETA: 0s - loss: 0.6873 - accuracy: 0.36 - ETA: 0s - loss: 0.6704 - accuracy: 0.39 - ETA: 0s - loss: 0.6351 - accuracy: 0.38 - ETA: 0s - loss: 0.6157 - accuracy: 0.38 - 0s 3ms/step - loss: 0.6156 - accuracy: 0.3904 - val_loss: 0.5279 - val_accuracy: 0.7280\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.65 - ETA: 0s - loss: 0.5328 - accuracy: 0.73 - ETA: 0s - loss: 0.5239 - accuracy: 0.72 - ETA: 0s - loss: 0.5630 - accuracy: 0.65 - ETA: 0s - loss: 0.5676 - accuracy: 0.61 - ETA: 0s - loss: 0.5672 - accuracy: 0.60 - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6079 - val_loss: 0.5537 - val_accuracy: 0.4918\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.40 - ETA: 0s - loss: 0.7326 - accuracy: 0.47 - ETA: 0s - loss: 0.7195 - accuracy: 0.47 - ETA: 0s - loss: 0.6569 - accuracy: 0.45 - ETA: 0s - loss: 0.6187 - accuracy: 0.48 - ETA: 0s - loss: 0.6090 - accuracy: 0.50 - 0s 2ms/step - loss: 0.6077 - accuracy: 0.5009 - val_loss: 0.6750 - val_accuracy: 0.5525\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.62 - ETA: 0s - loss: 0.7475 - accuracy: 0.52 - ETA: 0s - loss: 0.7063 - accuracy: 0.53 - ETA: 0s - loss: 0.7456 - accuracy: 0.55 - ETA: 0s - loss: 0.7392 - accuracy: 0.57 - 0s 2ms/step - loss: 0.7573 - accuracy: 0.5663 - val_loss: 0.6489 - val_accuracy: 0.2720\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7367 - accuracy: 0.31 - ETA: 0s - loss: 0.5919 - accuracy: 0.38 - ETA: 0s - loss: 0.5800 - accuracy: 0.34 - ETA: 0s - loss: 0.5689 - accuracy: 0.41 - ETA: 0s - loss: 0.5603 - accuracy: 0.48 - ETA: 0s - loss: 0.5449 - accuracy: 0.53 - 0s 2ms/step - loss: 0.5435 - accuracy: 0.5388 - val_loss: 0.5194 - val_accuracy: 0.7053\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.90 - ETA: 0s - loss: 0.5585 - accuracy: 0.63 - ETA: 0s - loss: 0.5272 - accuracy: 0.66 - ETA: 0s - loss: 0.5191 - accuracy: 0.68 - ETA: 0s - loss: 0.5097 - accuracy: 0.69 - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7052 - val_loss: 0.4584 - val_accuracy: 0.7484\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.65 - ETA: 0s - loss: 0.5292 - accuracy: 0.40 - ETA: 0s - loss: 0.5075 - accuracy: 0.44 - ETA: 0s - loss: 0.4978 - accuracy: 0.53 - ETA: 0s - loss: 0.4953 - accuracy: 0.57 - 0s 2ms/step - loss: 0.4962 - accuracy: 0.5653 - val_loss: 0.4679 - val_accuracy: 0.7280\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.81 - ETA: 0s - loss: 0.4769 - accuracy: 0.76 - ETA: 0s - loss: 0.5149 - accuracy: 0.75 - ETA: 0s - loss: 0.5251 - accuracy: 0.60 - ETA: 0s - loss: 0.5300 - accuracy: 0.53 - 0s 2ms/step - loss: 0.5339 - accuracy: 0.4966 - val_loss: 0.5505 - val_accuracy: 0.2533\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.21 - ETA: 0s - loss: 0.5836 - accuracy: 0.28 - ETA: 0s - loss: 0.5590 - accuracy: 0.29 - ETA: 0s - loss: 0.5564 - accuracy: 0.32 - ETA: 0s - loss: 0.5552 - accuracy: 0.30 - 0s 2ms/step - loss: 0.5472 - accuracy: 0.3020 - val_loss: 0.4898 - val_accuracy: 0.2737\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7116 - accuracy: 0.50 - ETA: 0s - loss: 0.5582 - accuracy: 0.44 - ETA: 0s - loss: 0.5850 - accuracy: 0.37 - ETA: 0s - loss: 0.5639 - accuracy: 0.40 - ETA: 0s - loss: 0.5546 - accuracy: 0.47 - 0s 2ms/step - loss: 0.5546 - accuracy: 0.5004 - val_loss: 0.5414 - val_accuracy: 0.7013\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 2.9091 - accuracy: 0.62 - ETA: 0s - loss: 1.2865 - accuracy: 0.41 - ETA: 0s - loss: 0.9933 - accuracy: 0.39 - ETA: 0s - loss: 0.8541 - accuracy: 0.42 - ETA: 0s - loss: 0.7678 - accuracy: 0.40 - ETA: 0s - loss: 0.7129 - accuracy: 0.43 - 0s 3ms/step - loss: 0.6911 - accuracy: 0.4782 - val_loss: 0.4958 - val_accuracy: 0.7269\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.68 - ETA: 0s - loss: 0.4642 - accuracy: 0.63 - ETA: 0s - loss: 0.4739 - accuracy: 0.51 - ETA: 0s - loss: 0.4880 - accuracy: 0.50 - ETA: 0s - loss: 0.4950 - accuracy: 0.49 - ETA: 0s - loss: 0.4974 - accuracy: 0.49 - 0s 2ms/step - loss: 0.4974 - accuracy: 0.4926 - val_loss: 0.4580 - val_accuracy: 0.6803\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.56 - ETA: 0s - loss: 0.5128 - accuracy: 0.54 - ETA: 0s - loss: 0.5202 - accuracy: 0.64 - ETA: 0s - loss: 0.4934 - accuracy: 0.65 - ETA: 0s - loss: 0.4947 - accuracy: 0.57 - 0s 2ms/step - loss: 0.4925 - accuracy: 0.5167 - val_loss: 0.4415 - val_accuracy: 0.2345\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.21 - ETA: 0s - loss: 0.5928 - accuracy: 0.27 - ETA: 0s - loss: 0.5581 - accuracy: 0.35 - ETA: 0s - loss: 0.5432 - accuracy: 0.47 - ETA: 0s - loss: 0.5262 - accuracy: 0.54 - ETA: 0s - loss: 0.5179 - accuracy: 0.54 - 0s 2ms/step - loss: 0.5180 - accuracy: 0.5485 - val_loss: 0.4673 - val_accuracy: 0.7899\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.68 - ETA: 0s - loss: 0.4526 - accuracy: 0.69 - ETA: 0s - loss: 0.4639 - accuracy: 0.56 - ETA: 0s - loss: 0.4769 - accuracy: 0.59 - ETA: 0s - loss: 0.4702 - accuracy: 0.62 - 0s 2ms/step - loss: 0.4749 - accuracy: 0.5933 - val_loss: 0.4471 - val_accuracy: 0.2584\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.28 - ETA: 0s - loss: 0.5339 - accuracy: 0.46 - ETA: 0s - loss: 0.5554 - accuracy: 0.38 - ETA: 0s - loss: 0.5384 - accuracy: 0.34 - ETA: 0s - loss: 0.5272 - accuracy: 0.31 - 0s 2ms/step - loss: 0.5207 - accuracy: 0.3105 - val_loss: 0.4494 - val_accuracy: 0.2311\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.15 - ETA: 0s - loss: 0.4783 - accuracy: 0.26 - ETA: 0s - loss: 0.4888 - accuracy: 0.47 - ETA: 0s - loss: 0.4867 - accuracy: 0.56 - ETA: 0s - loss: 0.4803 - accuracy: 0.59 - 0s 2ms/step - loss: 0.4778 - accuracy: 0.5825 - val_loss: 0.4288 - val_accuracy: 0.5696\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.62 - ETA: 0s - loss: 0.4504 - accuracy: 0.32 - ETA: 0s - loss: 0.4477 - accuracy: 0.32 - ETA: 0s - loss: 0.4580 - accuracy: 0.44 - ETA: 0s - loss: 0.4669 - accuracy: 0.51 - 0s 2ms/step - loss: 0.4686 - accuracy: 0.5464 - val_loss: 0.4389 - val_accuracy: 0.7819\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.75 - ETA: 0s - loss: 0.4662 - accuracy: 0.67 - ETA: 0s - loss: 0.4663 - accuracy: 0.57 - ETA: 0s - loss: 0.4598 - accuracy: 0.47 - ETA: 0s - loss: 0.4647 - accuracy: 0.50 - 0s 2ms/step - loss: 0.4641 - accuracy: 0.5333 - val_loss: 0.4638 - val_accuracy: 0.7314\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.78 - ETA: 0s - loss: 0.4648 - accuracy: 0.74 - ETA: 0s - loss: 0.4654 - accuracy: 0.71 - ETA: 0s - loss: 0.4719 - accuracy: 0.66 - ETA: 0s - loss: 0.4695 - accuracy: 0.65 - 0s 2ms/step - loss: 0.4647 - accuracy: 0.5841 - val_loss: 0.4510 - val_accuracy: 0.2720\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 1.5958 - accuracy: 0.53 - ETA: 0s - loss: 0.8456 - accuracy: 0.46 - ETA: 0s - loss: 0.7223 - accuracy: 0.55 - ETA: 0s - loss: 0.6744 - accuracy: 0.57 - ETA: 0s - loss: 0.6383 - accuracy: 0.58 - ETA: 0s - loss: 0.6147 - accuracy: 0.60 - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6198 - val_loss: 0.4986 - val_accuracy: 0.7098\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.75 - ETA: 0s - loss: 0.5303 - accuracy: 0.66 - ETA: 0s - loss: 0.5940 - accuracy: 0.66 - ETA: 0s - loss: 0.6856 - accuracy: 0.68 - ETA: 0s - loss: 0.7497 - accuracy: 0.69 - ETA: 0s - loss: 0.7556 - accuracy: 0.70 - 0s 2ms/step - loss: 0.7563 - accuracy: 0.7018 - val_loss: 0.7225 - val_accuracy: 0.7541\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7275 - accuracy: 0.71 - ETA: 0s - loss: 0.9376 - accuracy: 0.74 - ETA: 0s - loss: 0.8916 - accuracy: 0.73 - ETA: 0s - loss: 0.8398 - accuracy: 0.73 - ETA: 0s - loss: 0.7768 - accuracy: 0.72 - ETA: 0s - loss: 0.7505 - accuracy: 0.72 - 0s 2ms/step - loss: 0.7480 - accuracy: 0.7194 - val_loss: 0.6830 - val_accuracy: 0.6775\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.7785 - accuracy: 0.75 - ETA: 0s - loss: 0.9316 - accuracy: 0.64 - ETA: 0s - loss: 0.8589 - accuracy: 0.62 - ETA: 0s - loss: 0.7838 - accuracy: 0.61 - ETA: 0s - loss: 0.7193 - accuracy: 0.61 - ETA: 0s - loss: 0.6956 - accuracy: 0.60 - 0s 2ms/step - loss: 0.7019 - accuracy: 0.6015 - val_loss: 0.5063 - val_accuracy: 0.4577\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.40 - ETA: 0s - loss: 0.5208 - accuracy: 0.59 - ETA: 0s - loss: 0.5361 - accuracy: 0.64 - ETA: 0s - loss: 0.5546 - accuracy: 0.66 - ETA: 0s - loss: 0.5456 - accuracy: 0.63 - ETA: 0s - loss: 0.5503 - accuracy: 0.60 - 0s 2ms/step - loss: 0.5544 - accuracy: 0.6007 - val_loss: 0.7977 - val_accuracy: 0.6263\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.43 - ETA: 0s - loss: 0.6457 - accuracy: 0.63 - ETA: 0s - loss: 0.6152 - accuracy: 0.56 - ETA: 0s - loss: 0.6240 - accuracy: 0.52 - ETA: 0s - loss: 0.6053 - accuracy: 0.52 - 0s 2ms/step - loss: 0.6192 - accuracy: 0.5401 - val_loss: 0.6145 - val_accuracy: 0.6616\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.75 - ETA: 0s - loss: 0.5832 - accuracy: 0.65 - ETA: 0s - loss: 0.6252 - accuracy: 0.58 - ETA: 0s - loss: 0.6154 - accuracy: 0.55 - ETA: 0s - loss: 0.6343 - accuracy: 0.55 - ETA: 0s - loss: 0.6501 - accuracy: 0.58 - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5869 - val_loss: 0.6883 - val_accuracy: 0.7252\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.84 - ETA: 0s - loss: 0.5789 - accuracy: 0.68 - ETA: 0s - loss: 0.6546 - accuracy: 0.69 - ETA: 0s - loss: 0.7167 - accuracy: 0.70 - ETA: 0s - loss: 0.7619 - accuracy: 0.71 - ETA: 0s - loss: 0.7752 - accuracy: 0.71 - 0s 2ms/step - loss: 0.7752 - accuracy: 0.7136 - val_loss: 0.6365 - val_accuracy: 0.7212\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.75 - ETA: 0s - loss: 0.6515 - accuracy: 0.65 - ETA: 0s - loss: 0.6056 - accuracy: 0.69 - ETA: 0s - loss: 0.5857 - accuracy: 0.69 - ETA: 0s - loss: 0.5905 - accuracy: 0.70 - ETA: 0s - loss: 0.6239 - accuracy: 0.70 - 0s 2ms/step - loss: 0.6294 - accuracy: 0.7071 - val_loss: 0.5688 - val_accuracy: 0.7257\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.71 - ETA: 0s - loss: 0.6036 - accuracy: 0.51 - ETA: 0s - loss: 0.6095 - accuracy: 0.59 - ETA: 0s - loss: 0.6305 - accuracy: 0.61 - ETA: 0s - loss: 0.6218 - accuracy: 0.64 - ETA: 0s - loss: 0.6173 - accuracy: 0.61 - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6121 - val_loss: 0.5667 - val_accuracy: 0.4106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: dbf5344af5c3ff054f730dce7684ee28</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7641491293907166</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in ./tuner/hyperpar</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: dbf5344af5c3ff054f730dce7684ee28</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7641491293907166</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 14165ec167e47c62010e9d2a6f6ad3fd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7083096702893575</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: eb796609627ab57c14431dfdc7517679</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7005489269892374</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 480</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b78eabf5e408f05d3e158013b0de9cce</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6806738575299581</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9d58dcc0b69a704bf8515ab29f8b0acd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6566344896952311</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
